{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# open image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('image_28.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('show image',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "k=cv2.waitKey(0)\n",
    "if k==27:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# open vidoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import datetime\n",
    "cap=cv2.VideoCapture(0)\n",
    "fourcc=cv2.VideoWriter_fourcc(*'XVID')\n",
    "outi=cv2.VideoWriter('outi.avi',fourcc,20.0,(640,480))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cap.isOpened())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "        \n",
    "    print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    #frame=cv2.flip(frame,0)\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    outi.write(frame)  \n",
    "    cv2.imshow('frame',gray)\n",
    "    if cv2.waitKey(1)==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "outi.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#/////////////////////////////////"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# draw shapes on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=np.zeros([512,512,3],np.uint8)\n",
    "#img=cv2.line(img,(0,0),(256,256),(0,0,255),5)\n",
    "#img=cv2.arrowedLine(img,(0,255),(256,256),(0,0,255),5)\n",
    "#img=cv2.rectangle(img,(384,0),(510,128),(255,0,0),20)\n",
    "#img=cv2.circle(img,(256,256),63,(0,0,255,0),20)\n",
    "#font=cv2.FONT_HERSHEY_COMPLEX\n",
    "#img=cv2.putText(img,'ahmed',(10,100),font,4,(0,255,255),10)\n",
    "pts=np.array([[50,50],[100,80],[100,160],[200,100]],np.int32)\n",
    "img=cv2.polylines(img,[pts],True,(0,255,255))\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create shape(sun , ..........)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "img=np.zeros((600,900,3),dtype=np.uint8)\n",
    "#background\n",
    "cv.rectangle(img,(0,0),(900,500),(255,225,85),-1)\n",
    "cv.rectangle(img,(0,500),(900,600),(75,180,70),-1)\n",
    "\n",
    "#sun\n",
    "cv.circle(img,(200,150),60,(0,255,255),-1)\n",
    "cv.circle(img,(200,150),70,(220,255,255),10)\n",
    "\n",
    "#tree\n",
    "cv.line(img,(710,500),(710,420),(30,65,155),15)\n",
    "\n",
    "trang=np.array([[640,460],[780,460],[710,200]],dtype=np.int32)\n",
    "cv.fillPoly(img,[trang],(75,180,80))\n",
    "#tree2\n",
    "cv.line(img,(600,500),(600,420),(30,65,155),25)\n",
    "\n",
    "trang1=np.array([[500,440],[700,440],[600,75]],dtype=np.int32)\n",
    "cv.fillPoly(img,[trang1],(75,180,80))\n",
    "\n",
    "font=cv.FONT_HERSHEY_COMPLEX\n",
    "img=cv.putText(img,'ahmed kaled',(120,490),font,1.5,(255,255,255),2)\n",
    "\n",
    "cv.imwrite('tree.png',img)\n",
    "cv.imshow('tree', img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set width , height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap=cv2.VideoCapture(0)\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "cap.set(3,10000)\n",
    "cap.set(4,10000)\n",
    "\n",
    "print(cap.get(3))\n",
    "print(cap.get(4))\n",
    "while cap.isOpened():\n",
    "    ret,frame=cap.read()\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    # Our operations on the frame come here\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', gray)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import datetime\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re=model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('show image',re)\n",
    "k=cv2.waitKey(0)\n",
    "if k==27:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import datetime\n",
    "cap=cv2.VideoCapture(0)\n",
    "fourcc=cv2.VideoWriter_fourcc(*'XVID')\n",
    "out=cv2.VideoWriter('out.avi',fourcc,20.0,(640,480))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cap.isOpened())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "        \n",
    "    print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    #frame=cv2.flip(frame,0)\n",
    "    font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "    text='width: '+str(cap.get(3))+' height: '+str(cap.get(4))\n",
    "    date=str(datetime.datetime.now())\n",
    "    frame=cv2.putText(frame,text,(10,100),font,1,(0,255,255),2)\n",
    "    frame=cv2.putText(frame,date,(10,450),font,1,(0,255,255),2)\n",
    "   \n",
    "    #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    out.write(frame) \n",
    "    #print(results)\n",
    "    cv2.imshow('frame',frame)\n",
    "    \n",
    "    print(ss[18:27])\n",
    "    if cv2.waitKey(1)==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mouse events 8-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EVENT_FLAG_ALTKEY', 'EVENT_FLAG_CTRLKEY', 'EVENT_FLAG_LBUTTON', 'EVENT_FLAG_MBUTTON', 'EVENT_FLAG_RBUTTON', 'EVENT_FLAG_SHIFTKEY', 'EVENT_LBUTTONDBLCLK', 'EVENT_LBUTTONDOWN', 'EVENT_LBUTTONUP', 'EVENT_MBUTTONDBLCLK', 'EVENT_MBUTTONDOWN', 'EVENT_MBUTTONUP', 'EVENT_MOUSEHWHEEL', 'EVENT_MOUSEMOVE', 'EVENT_MOUSEWHEEL', 'EVENT_RBUTTONDBLCLK', 'EVENT_RBUTTONDOWN', 'EVENT_RBUTTONUP']\n"
     ]
    }
   ],
   "source": [
    "ev=[i for i in dir(cv2) if 'EVENT' in i]\n",
    "print (ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def click(ev,x,y,flags,param):\n",
    "        if ev==cv2.EVENT_LBUTTONDOWN:\n",
    "                print(x,' , ',y)\n",
    "                font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "                strxy=str(x)+' , '+str(y)\n",
    "                cv2.putText(img,strxy,(x,y),font, .5,(255,255,0),2)\n",
    "                cv2.imshow('image',img)\n",
    "        if ev==cv2.EVENT_RBUTTONDOWN:\n",
    "                blue=img[y,x,0]\n",
    "                green=img[y,x,1]\n",
    "                red=img[y,x,2]\n",
    "                font=cv2.FONT_HERSHEY_SIMPLEX \n",
    "                strBGR='[ '+str(blue)+' , '+str(green)+' , '+str(red)+' ]'\n",
    "                cv2.putText(img,strBGR,(x,y),font, .5,(0,245,255),2)\n",
    "                cv2.imshow('image',img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72  ,  173\n",
      "291  ,  229\n",
      "291  ,  229\n",
      "260  ,  262\n"
     ]
    }
   ],
   "source": [
    "img=cv2.imread('unnamed.jpg')\n",
    "cv2.imshow('image',img)\n",
    "\n",
    "cv2.setMouseCallback('image',click)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def click(ev,x,y,flags,param):\n",
    "    if ev==cv2.EVENT_LBUTTONDOWN:\n",
    "        cv2.circle(img,(x,y),3,(255,0,0),-1)\n",
    "        points.append((x,y))\n",
    "        if len(points)>=2:\n",
    "            cv2.line(img,points[-1],points[-2],(0,255,255))\n",
    "        cv2.imshow('image',img)\n",
    "img=np.zeros((512,512,3),dtype=np.uint8)\n",
    "cv2.imshow('image',img)\n",
    "points=[]\n",
    "\n",
    "cv2.setMouseCallback('image',click)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def click(ev,x,y,flags,param):\n",
    "    if ev==cv2.EVENT_LBUTTONDOWN:\n",
    "        blue= img[y,x,0]\n",
    "        green= img[y,x,1] \n",
    "        red= img[y,x,2]\n",
    "        mycolorimg=np.zeros((512,512,3),dtype=np.uint8)\n",
    "        mycolorimg[:]=[blue,green,red]\n",
    "        \n",
    "        cv2.imshow('image',mycolorimg)\n",
    "        \n",
    "img=cv2.imread('unnamed.jpg')\n",
    "cv2.imshow('image',img)\n",
    "\n",
    "\n",
    "cv2.setMouseCallback('image',click)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11 ,12 no code  but in notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13 trackbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def nothing(x):\n",
    "    print(x)\n",
    "    \n",
    "img=np.zeros((300,512,3),dtype=np.uint8)\n",
    "cv2.namedWindow('image')\n",
    "\n",
    "cv2.createTrackbar('B', 'image',0,255,nothing)\n",
    "cv2.createTrackbar('G', 'image',0,255,nothing)\n",
    "cv2.createTrackbar('R', 'image',0,255,nothing)\n",
    "\n",
    "switch='0 :off\\n 1 :on'\n",
    "cv2.createTrackbar(switch, 'image',0,1,nothing)\n",
    "\n",
    "while(True):\n",
    "    cv2.imshow('image',img)\n",
    "    \n",
    "    k=cv2.waitKey(1)\n",
    "    if k==27:\n",
    "        break\n",
    "        \n",
    "    b=cv2.getTrackbarPos('B', 'image')\n",
    "    g=cv2.getTrackbarPos('G', 'image')\n",
    "    r=cv2.getTrackbarPos('R', 'image')\n",
    "    \n",
    "    s=cv2.getTrackbarPos(switch, 'image')\n",
    "    \n",
    "    \n",
    "    if s==0:\n",
    "        img[:]=0\n",
    "    else:\n",
    "        img[:]=[b,g,r]\n",
    "        \n",
    "  \n",
    "    \n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# object detection and trackbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "while(True):\n",
    "    frame=cv2.imread('aks.png.jpg')\n",
    "    hsv=cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    lower=np.array([22,93,0])\n",
    "    upper=np.array([45,255,255])\n",
    "    \n",
    "    mask=cv2.inRange(hsv,lower,upper)\n",
    "    \n",
    "    res=cv2.bitwise_and(frame,frame,mask=mask)\n",
    "    \n",
    "    cv2.imshow(\"hsv\",hsv)\n",
    "    cv2.imshow(\"detection\",frame)\n",
    "    cv2.imshow('mask',mask)\n",
    "    cv2.imshow('res',res)\n",
    "    \n",
    "    k=cv2.waitKey(0)\n",
    "    if k==27:\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "def nothing(x):\n",
    "    print(x)\n",
    "    \n",
    "cv2.namedWindow('tracking')\n",
    "\n",
    "cv2.createTrackbar('lh', 'tracking',0,255,nothing)\n",
    "cv2.createTrackbar('ls', 'tracking',0,255,nothing)\n",
    "cv2.createTrackbar('lv', 'tracking',0,255,nothing)\n",
    "\n",
    "cv2.createTrackbar('uh', 'tracking',255,255,nothing)\n",
    "cv2.createTrackbar('us', 'tracking',255,255,nothing)\n",
    "cv2.createTrackbar('uv', 'tracking',255,255,nothing)\n",
    "\n",
    "while (True):\n",
    "    frame=cv2.imread('aks.png.jpg')\n",
    "    hsv=cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "   \n",
    "    l_h=cv2.getTrackbarPos('lh', 'tracking')\n",
    "    l_s=cv2.getTrackbarPos('ls', 'tracking')\n",
    "    l_v=cv2.getTrackbarPos('lv', 'tracking')\n",
    "\n",
    "    u_h=cv2.getTrackbarPos('uh', 'tracking')\n",
    "    u_s=cv2.getTrackbarPos('us', 'tracking')\n",
    "    u_v=cv2.getTrackbarPos('uv', 'tracking')\n",
    "    print('********')\n",
    "    print(l_h)\n",
    "    print(l_s)\n",
    "    print(l_v)\n",
    "    print('********')\n",
    "    print(u_h)\n",
    "    print(u_s)\n",
    "    print(u_v)\n",
    "    l_y=np.array([l_h,l_s,l_v])\n",
    "    u_y=np.array([u_h,u_s,u_v])\n",
    "    print('//////////')\n",
    "    print(l_y)\n",
    "    print(u_y)\n",
    "    mask=cv2.inRange(hsv,l_y,u_y)\n",
    "    res=cv2.bitwise_and(frame,frame,mask=mask)\n",
    "    \n",
    "    \n",
    "    cv2.imshow(\"frame\",frame)\n",
    "    cv2.imshow('mask',mask)\n",
    "    cv2.imshow('res',res)\n",
    "    \n",
    "    k=cv2.waitKey(0)\n",
    "    if k==27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# threshold using adaptiveThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "img=cv.imread('sudoku.png',0)\n",
    "_,th1=cv.threshold(img,127,255,cv.THRESH_BINARY)\n",
    "th2=cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_MEAN_C,cv.THRESH_BINARY,111,2)\n",
    "th3=cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C,cv.THRESH_BINARY,111,2)\n",
    "\n",
    "cv.imshow('image',img)\n",
    "cv.imshow('THRESH_BINARY',th1)\n",
    "cv.imshow('ADAPTIVE_THRESH_MEAN_C',th2)\n",
    "cv.imshow('ADAPTIVE_THRESH_GAUSSIAN_C',th3)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18 morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img=cv2.imread('mask.png')\n",
    "gray=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "_,mask=cv2.threshold(gray,127,255,cv2.THRESH_BINARY_INV)\n",
    "\n",
    "kernal=np.ones((5,5),dtype=np.uint8)\n",
    "dil=cv2.dilate(mask,kernal,iterations=2)\n",
    "erosion=cv2.erode(mask,kernal,iterations=2)\n",
    "\n",
    "opening=cv2.morphologyEx(mask,cv2.MORPH_OPEN,kernal,iterations=1)\n",
    "closing=cv2.morphologyEx(mask,cv2.MORPH_CLOSE,kernal,iterations=1)\n",
    "\n",
    "cv2.imshow('gray',img)\n",
    "cv2.imshow('mask',mask)\n",
    "cv2.imshow('after dilation',dil)\n",
    "cv2.imshow('after erosion',erosion)\n",
    "\n",
    "cv2.imshow('after opening',opening)\n",
    "cv2.imshow('after closing',closing)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img=cv2.imread('salt.jpg')\n",
    "\n",
    "avarag=cv2.blur(img,(5,5))\n",
    "gblur=cv2.GaussianBlur(img,(5,5),0)\n",
    "medien=cv2.medianBlur(img,5)\n",
    "bilaterlfilter=cv2.bilateralFilter(img,9,75,75)\n",
    "\n",
    "cv2.imshow('img',img)\n",
    "cv2.imshow('avarag',avarag)\n",
    "\n",
    "cv2.imshow('gblur',gblur)\n",
    "cv2.imshow('medien',medien)\n",
    "cv2.imshow('bilaterlfilter',bilaterlfilter)\n",
    "\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img=cv2.imread('sudoku.png',0)\n",
    "\n",
    "lap=cv2.Laplacian(img,cv2.CV_64F,ksize=3)\n",
    "lap=np.uint8(np.absolute(lap))\n",
    "\n",
    "\n",
    "# Sobel Edge Detection\n",
    "sobelx = cv2.Sobel(src=img, ddepth=cv2.CV_64F, dx=1, dy=0)\n",
    "soble_y=cv2.Sobel(img,cv2.CV_64F,0,1)\n",
    "\n",
    "soble_x=np.uint8(np.absolute(sobelx))\n",
    "soble_y=np.uint8(np.absolute(soble_y))\n",
    "\n",
    "combine=cv2.bitwise_or(soble_x,soble_y)\n",
    "\n",
    "canny=cv2.Canny(img,0,90)\n",
    "\n",
    "cv2.imshow('img',img)\n",
    "cv2.imshow('Laplacian',lap)\n",
    "cv2.imshow('soble_x',soble_x)\n",
    "cv2.imshow('soble_y',soble_y)\n",
    "cv2.imshow('combine',combine)\n",
    "cv2.imshow('canny',canny)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# image pyramids and blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "image=cv2.imread('lene.jfif')\n",
    "gaussian = []  \n",
    "gaussian_layer= image.copy() \n",
    "\n",
    "for i in range(6):\n",
    "    gaussian_layer = cv2.pyrDown(gaussian_layer)\n",
    "    gaussian.append(gaussian_layer)\n",
    "    #cv2.imshow('Gaussian Layer -{}'.format(i),gaussian_layer)\n",
    "    \n",
    "laplacian = [gaussian[-1]] \n",
    "\n",
    "for i in range(5,0,-1):\n",
    "    size = (gaussian[i - 1].shape[1], gaussian[i - 1].shape[0])\n",
    "    gaussian_expanded = cv2.pyrUp(gaussian[i], dstsize=size)\n",
    "    laplacian_layer = cv2.subtract(gaussian[i-1], gaussian_expanded)\n",
    "    laplacian.append(laplacian_layer)\n",
    "    #cv2.imshow('laplacian layer -{}'.format(i-1),laplacian_layer)\n",
    "\n",
    "imgg=cv2.pyrUp(laplacian[5])\n",
    "cv2.imshow('img',imgg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "img=cv2.imread('lene.jfif')\n",
    "img1=cv2.imread('salt.jpg')\n",
    "img= cv2.resize(img , (256,256))\n",
    "\n",
    "#imag1\n",
    "gaussian = []  \n",
    "gaussian_layer= img1.copy() \n",
    "\n",
    "for i in range(6):\n",
    "    gaussian_layer = cv2.pyrDown(gaussian_layer)\n",
    "    gaussian.append(gaussian_layer)\n",
    "    \n",
    "laplacian = [gaussian[-1]] \n",
    "for i in range(5,0,-1):\n",
    "    size = (gaussian[i - 1].shape[1], gaussian[i - 1].shape[0])\n",
    "    gaussian_expanded = cv2.pyrUp(gaussian[i], dstsize=size)\n",
    "    laplacian_layer = cv2.subtract(gaussian[i-1], gaussian_expanded)\n",
    "    laplacian.append(laplacian_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img.shape)\n",
    "print(img1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image2\n",
    "gaus = []  \n",
    "gaus_layer= img.copy() \n",
    "\n",
    "for i in range(6):\n",
    "    gaus_layer = cv2.pyrDown(gaus_layer)\n",
    "    gaus.append(gaus_layer)\n",
    "    \n",
    "laplac = [gaus[-1]] \n",
    "for i in range(5,0,-1):\n",
    "    sizee = (gaus[i - 1].shape[1], gaus[i - 1].shape[0])\n",
    "    gaus_expanded = cv2.pyrUp(gaus[i], dstsize=sizee)\n",
    "    laplac_layer = cv2.subtract(gaus[i-1], gaus_expanded)\n",
    "    laplac.append(laplac_layer)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs=[]\n",
    "for img11,img22 in zip (laplacian,laplac):\n",
    "    cols,rows,ch=img11.shape\n",
    "    lapalci=np.hstack((img11[:,0:int(cols/2)],img22[:,int(cols/2):]))\n",
    "    imgs.append(lapalci)\n",
    "\n",
    "#reconstruct\n",
    "img_reconstruct=imgs[0]\n",
    "for i in range(1,6):\n",
    "    img_reconstruct=cv2.pyrUp(img_reconstruct)\n",
    "    img_reconstruct=cv2.add(imgs[i],img_reconstruct)\n",
    "img_reconstruct=cv2.pyrUp(img_reconstruct)\n",
    "\n",
    "cv2.imshow('img',img)\n",
    "cv2.imshow('img1',img1)\n",
    "\n",
    "cv2.imshow('img_reconstruct',img_reconstruct)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# car counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "\n",
    "w_min=80 #Largura minima do retangulo\n",
    "h_min=80 #Altura minima do retangulo\n",
    "\n",
    "offset=6 #Erro permitido entre pixel  \n",
    "\n",
    "y1=550 #Posição da linha de contagem \n",
    "\n",
    "delay=60\n",
    "detec=[]\n",
    "carr=0\n",
    "\n",
    "def pega_centro(x, y, w, h):\n",
    "    x1 = int(w / 2)\n",
    "    y1 = int(h / 2)\n",
    "    cx = x + x1\n",
    "    cy = y + y1\n",
    "    return cx,cy\n",
    "\n",
    "cap = cv2.VideoCapture('video.mp4')\n",
    "bgs = cv2.createBackgroundSubtractorMOG2()\n",
    "kernal=np.ones((5,5),dtype=np.uint8)\n",
    "while True:\n",
    "    ret , frame1 = cap.read()\n",
    "    \n",
    "\n",
    "    grey = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(grey,(3,3),10)\n",
    "    img_sub = bgs.apply(blur)\n",
    "    erode = cv2.erode(img_sub,kernal,iterations=5)\n",
    "   \n",
    "    #kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    #dilatada = cv2.morphologyEx (dilat, cv2. MORPH_CLOSE , kernel)\n",
    "    #dilatada = cv2.morphologyEx (dilatada, cv2. MORPH_CLOSE , kernel)\n",
    "    \n",
    "    contor,h=cv2.findContours(erode,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    cv2.line(frame1, (25, y1), (1200, y1), (255,127,0), 3) \n",
    "    \n",
    "    for (i,c) in enumerate(contor):\n",
    "        (x,y,w,h)=cv2.boundingRect(c)\n",
    "        \n",
    "        validar_cont=(w>=w_min)and(h>=h_min)\n",
    "        if not validar_cont:\n",
    "            continue\n",
    "        cv2.rectangle(frame1,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        centro = pega_centro(x, y, w, h)\n",
    "        detec.append(centro)\n",
    "        cv2.circle(frame1, centro, 4, (0, 0,255), -1)\n",
    "        \n",
    "        for(x,y) in detec:\n",
    "            if(y<(y1+offset))and(y>(y1-offset)):\n",
    "                carr+=1\n",
    "                cv2.line(frame1, (25, y1), (1200, y1), (0,127,255), 3)\n",
    "                detec.remove((x,y))\n",
    "                print(\"no. of cars detected : \" + str(carr))\n",
    "                \n",
    "        cv2.putText(frame1, \"VEHICLE COUNT : \"+str(carr), (450, 70), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255),5)\n",
    "        cv2.imshow(\"Video Original\" , frame1)\n",
    "        cv2.imshow(\"Detectar\",img_sub)\n",
    "\n",
    "        if cv2.waitKey(1)==ord('q'):\n",
    "            break\n",
    "if cv2.waitKey(1)==ord('q'):\n",
    "            break\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "                \n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# shepes detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img=cv2.imread('color.png')\n",
    "gray=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "_,thresh=cv2.threshold(gray,127,255,cv2.THRESH_BINARY_INV)\n",
    "\n",
    "contor,h=cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "cv2.imshow(\"imag\",img)\n",
    "font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "for cont in contor:\n",
    "    approx=cv2.approxPolyDP(cont,0.01*cv2.arcLength(cont,True),True)\n",
    "    cv2.drawContours(img,[approx],0,(0,0,0),5)\n",
    "    x=approx.ravel()[0]\n",
    "    y=approx.ravel()[1]\n",
    "    if len(approx)==3:\n",
    "        print(approx)\n",
    "        cv2.putText(img,\"triangle\",(x,y),font,0.5,(0,0,0))\n",
    "    \n",
    "    elif len(approx)==4:\n",
    "        x,y,w,h=cv2.boundingRect(approx)\n",
    "        asp=float(w)/h\n",
    "        \n",
    "        if asp>=0.95 and asp<=1.05:\n",
    "            cv2.putText(img,\"square\",(x,y),font,0.5,(0,0,0))\n",
    "        else:\n",
    "            cv2.putText(img,\"rectangle\",(x,y),font,0.5,(0,0,0))\n",
    "            \n",
    "    elif len(approx)==5:\n",
    "        cv2.putText(img,\"pentagon\",(x,y),font,0.5,(0,0,0))\n",
    "        \n",
    "    elif len(approx)==10:\n",
    "        cv2.putText(img,\"star\",(x,y),font,0.5,(0,0,0))\n",
    "        \n",
    "    else:\n",
    "        cv2.putText(img,\"pentagon\",(x,y),font,0.5,(0,0,0))\n",
    "        \n",
    "             \n",
    "cv2.imshow(\"shape\",img) \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# otsu segmentation 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "img=cv.imread('lene.jfif',0)\n",
    "_,th1=cv.threshold(img,127,255,cv.THRESH_BINARY)\n",
    "_,th2=cv.threshold(img,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "\n",
    "cv.imshow('image',img)\n",
    "cv.imshow('THRESH_BINARY',th1)\n",
    "cv.imshow('THRESH_OTSU',th2)\n",
    "\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# templet matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv.imread('lene.jfif')\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img2 = img_gray.copy()\n",
    "template = cv.imread('lenee.jfif',0)\n",
    "w, h = template.shape[::-1]\n",
    "# All the 6 methods for comparison in a list\n",
    "methods = ['cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED', 'cv.TM_CCORR',\n",
    "            'cv.TM_CCORR_NORMED', 'cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED']\n",
    "for meth in methods:\n",
    "    img = img2.copy()\n",
    "    method = eval(meth)\n",
    "    # Apply template Matching\n",
    "    res = cv.matchTemplate(img,template,method)\n",
    "    min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)\n",
    "    # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n",
    "    if method in [cv.TM_SQDIFF, cv.TM_SQDIFF_NORMED]:\n",
    "        top_left = min_loc\n",
    "    else:\n",
    "        top_left = max_loc\n",
    "    bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "    cv.rectangle(img,top_left, bottom_right, 255, 2)\n",
    "    plt.subplot(1,2,1),plt.imshow(res,cmap = 'gray')\n",
    "    plt.title('Matching Result'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(1,2,2),plt.imshow(img,cmap = 'gray')\n",
    "    plt.title('Detected Point'), plt.xticks([]), plt.yticks([])\n",
    "    plt.suptitle(meth)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to illustrate\n",
    "# template matching\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read the main image\n",
    "img_rgb = cv2.imread('lene.jfif',0)\n",
    "\n",
    "# Convert it to grayscale\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Read the template\n",
    "template = cv2.imread('lenee.jfif',0)\n",
    "\n",
    "# Store width and height of template in w and h\n",
    "w, h = template.shape[::-1]\n",
    "\n",
    "# Perform match operations.\n",
    "res = cv2.matchTemplate(img_gray, template, cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "# Specify a threshold\n",
    "threshold = 0.99\n",
    "\n",
    "# Store the coordinates of matched area in a numpy array\n",
    "loc = np.where(res >= threshold)\n",
    "\n",
    "# Draw a rectangle around the matched region.\n",
    "for pt in zip(*loc[::-1]):\n",
    "    cv2.rectangle(img_rgb, pt, (pt[0] + w, pt[1] + h), (0, 255, 255), 2)\n",
    "\n",
    "# Show the final image with the matched area.\n",
    "cv2.imshow('Detected', img_rgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label='unknown'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "video_capture = cv2.VideoCapture('E:/machine learning/my final project/project.mp4')\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceCascade.detectMultiScale(gray,\n",
    "                                         scaleFactor=1.1,\n",
    "                                         minNeighbors=5,\n",
    "                                         minSize=(60, 60),\n",
    "                                         flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h),(0,255,0), 2)\n",
    "        cv2.putText(frame,label,(x,y-4),cv2.FONT_HERSHEY_COMPLEX,0.8,(255,255,255),2)\n",
    "        # Display the resulting frame\n",
    "    cv2.imshow('Video', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN\n",
    "import cv2\n",
    "mtcnn = MTCNN(image_size=160, margin=14, min_face_size=20,device='cpu', post_process=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    boxes, probs = mtcnn.detect(frame, landmarks=False)\n",
    "    if  not probs.all() == None and probs.all()> 0.6 :\n",
    "        for face in boxes:\n",
    "                x, y, width, height = face['box']\n",
    "                x2, y2 = x + width, y + height\n",
    "                cv2.rectangle(frame, (x, y), (x2, y2), (0, 0, 255), 4)\n",
    "                cv2.putText(frame,'face',(x1,y1),cv2.FONT_HERSHEY_COMPLEX,0.8,(255,255,255),2)\n",
    "        cv2.imshow('Video', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "detector = MTCNN()\n",
    "\n",
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "while (True):\n",
    "    ret, frame = video.read()\n",
    "    if ret == True:\n",
    "        location = detector.detect_faces(frame)\n",
    "        if len(location) > 0:\n",
    "            for face in location:\n",
    "                x, y, width, height = face['box']\n",
    "                x2, y2 = x + width, y + height\n",
    "                cv2.rectangle(frame, (x, y), (x2, y2), (0, 0, 255), 4)\n",
    "        cv2.imshow(\"Output\",frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('data/haarcascades/haarcascade_eye.xml')\n",
    "\n",
    "cap = cv2.VideoCapture('http://192.168.1.2:8080/video')\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import requests\n",
    "import io\n",
    "\n",
    "ip = input(\"Enter the ipv4 address for your ip webcam: \")\n",
    "url = ip + \"/shot.jpg\"\n",
    "while True:\n",
    "\n",
    "    img_request = requests.get(url)\n",
    "    img_arrint = np.array(bytearray(img_request.content), dtype=np.uint8)\n",
    "    img = cv2.imdecode(img_arrint, -1)\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceCascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),3)\n",
    "        cv2.putText(img,'Face',(x,y-4),cv2.FONT_HERSHEY_COMPLEX,0.8,(255,255,255),2)\n",
    "        \n",
    "        eye=eye_cascade.detectMultiScale(gray,2.3,4)\n",
    "        for(ex,ey,ew,eh)in eye:\n",
    "            cv2.rectangle(img,(ex,ey),(ex+ew,ey+eh),(0,255,0),5)\n",
    "            cv2.putText(img,'Eye',(ex,ey-3),cv2.FONT_HERSHEY_COMPLEX,0.8,(255,255,255),2)\n",
    "        \n",
    "        \n",
    "    cv2.imshow(\"video-stream\", img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# face landmarks using dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector=dlib.get_frontal_face_detector()\n",
    "predector=dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "while True:\n",
    "    _,frame=cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces=detector(gray)\n",
    "    for face in faces:\n",
    "        x1=face.left()\n",
    "        y1=face.top()\n",
    "        x2=face.right()\n",
    "        y2=face.bottom()\n",
    "        cv2.rectangle(frame,(x1,y1),(x2,y2),(0,255,0),3)\n",
    "        landmarks=predector(gray,face)\n",
    "        for n in range(0,68):\n",
    "            x=landmarks.part(n).x\n",
    "            y=landmarks.part(n).y\n",
    "            cv2.circle(frame,(x,y),3,(0,0,255),-1)\n",
    "            \n",
    "    cv2.imshow(\"my face\",frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "while True:\n",
    "    _,frame=cap.read()\n",
    "    mp_f_mesh=mp.solutions.face_mesh.FaceMesh()\n",
    "    rgb_img=cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "    res=mp_f_mesh.process(rgb_img)\n",
    "    \n",
    "    h,w,_=frame.shape\n",
    "    \n",
    "    for f in res.multi_face_landmarks:\n",
    "        for i in range(0,468):\n",
    "            pt1=f.landmark[i]\n",
    "            print(pt1)\n",
    "            x=int(pt1.x*w)\n",
    "            y=int(pt1.y*h)\n",
    "            cv2.circle(frame,(x,y),2,(100,100,0),-1)\n",
    "    \n",
    "            \n",
    "    cv2.imshow(\"my face\",frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install facenet-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
